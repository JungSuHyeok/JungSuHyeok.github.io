<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>PART II 데이터분석 및 전처리</title>
</head>
<body><h1>데이터 전처리</h1>
<p>&nbsp;</p>
<p> 인공지능 모델이 좋은 성능을 발휘하기 위해서는 좋은 데이터들로 학습되어야 한다. 따라서 학습 데이터를 모델이 적절하게 학습하도록 전처리를 해야한다. 전처리의 종류에는 많은 것들이 있지만 거의 필수적으로 해야하는 전처리는 3가지 정도가 있다.</p>
<p>&nbsp;</p>
<ol start='' >
<li>결측치 처리 및 필요없는 데이터 삭제</li>
<li>카테고리형 데이터 및 텍스트 데이터 더미처리</li>
<li>스케일링</li>

</ol>
<p>&nbsp;</p>
<pre><code class='language-python' lang='python'>import pandas as pd
import numpy as np

housing = pd.read_csv(&#39;/content/drive/MyDrive/housing.csv&#39;)
</code></pre>
<p>&nbsp;</p>
<p><strong> 결측치 처리 및 데이터 삭제</strong></p>
<pre><code class='language-python' lang='python'>housing.isnull().sum()
</code></pre>
<p>출력 :  <img src="C:\Users\User\AppData\Roaming\Typora\typora-user-images\image-20231001162515155.png" referrerpolicy="no-referrer" alt="image-20231001162515155"></p>
<p>total_bedrooms의 207개의 결측치를 처리해야 함을 알 수 있다.</p>
<p>3가지 처리방법</p>
<pre><code class='language-python' lang='python'>housing.dropna(subset = [&#39;total_bedrooms&#39;]) #해당 구역을 제거(행을 제거)
housing.drop(&#39;total_bedrooms&#39;,axis = 1) #해당 피쳐값을 아예 제거(열을 제거)
housing[&#39;total_bedrooms&#39;].fillna(housing[&#39;total_bedrooms&#39;].median(),inplace = True) #다른 값들의 중앙값으로 대체
</code></pre>
<p>&nbsp;</p>
<p>207개의 행을 삭제하여 결측치를 없애는 방법, total_bedrooms를 아예 데이터에서 지워버리는 방법 그리고 결측치있는 부분을 total_bedrooms의 중앙값(어떤 경우에는 평균값 또는 0)으로 대체하는 방법이 있다. 지금은 중앙값이 가장 적절해 보이므로 3번 방법을 선택한다.</p>
<p>&nbsp;</p>
<p>데이터를 전반적으로 훑어본 후에 특정 피쳐값은 모델 학습에 전혀 도움이 될 것 같지 않은 특성이거나, 결측치가 너무 많아서 평균값이나 0으로 대체하기에 무리가 있다고 판단되는 데이터들은 결측치를 다른값으로 대체하기 보다는 그 피쳐값 자체를 제거하는 것이 유리할 때가 많다.</p>
<p>&nbsp;</p>
<p>sklearn 에는 결측치 처리를 위한 클래스가 존재한다.</p>
<pre><code class='language-python' lang='python'>from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy = &#39;median&#39;)
</code></pre>
<p>&nbsp;</p>
<p>중앙값은 수치에만 적용할 수 있으므로 텍스트형 데이터는 제거하고 다뤄야한다.</p>
<pre><code class='language-python' lang='python'>housing_num = housing.drop(&#39;ocean_proximity&#39;,axis = 1)

imputer.fit(housing_num)
X = imputer.transform(housing_num) #학습이 된 imputer를 housing_num에 적용 후 X에 저장
housing_tr = pd.DataFrame(X,columns = housing_num.columns,index = housing_num.index)
</code></pre>
<p>imputer를 학습시킨 후(각 피쳐값들의 중앙값 학습됨) X에 적용하여 결측치를 중앙값으로 대체한다. 전처리 후에는 X에 numpy에 array형태로 저장되므로 데이터 프레임으로 바꿔주려면 pd.DataFrame 함수를 사용해야 한다.</p>
<p>&nbsp;</p>
<p><strong>텍스트와 카테고리 특성 처리</strong></p>
<p>&nbsp;</p>
<p>위에서 결측치를 다뤘는데 ocean_proximity는 텍스트형 카테고리 피쳐값이다. 인공지능은 텍스트를 처리할 수 없으므로 적절한 숫자로 바꿔줘야 한다.</p>
<p>이는 OrdinalEncoder와 조금더 발전된 OneHotEncoder로 쉽게 구현할 수 있다.</p>
<pre><code class='language-python' lang='python'>from sklearn.preprocessing import OrdinalEncoder #카테고리를 텍스트 -&gt; 숫자로 변환해주는 클래스

ordinal_encoder = OrdinalEncoder() #문제점 : 인덱스가 가까운 두 값이 멀리 떨어진 두 값보다 비슷하다고 머신러닝 알고리즘이 인식할 수 있음.
housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)
</code></pre>
<p>&nbsp;</p>
<p>Ordinal Encoder는 OCEAN , INLAND , ISLAND , NEAR BAY , NEAR OCEAN 을 각각 0,1,2,3,4로 변환해 준다. 그러나 학습모델은 인덱스가 가까운(예를들어 2번과 3번인 ISLAND와 NEAR BAY)피쳐 값을 연관성이 있는 것으로 본다. 이는 실제로 그런것이 아니기 때문에 이를 해결하기 위해 &#39;더미처리&#39; 를 한다.</p>
<p>&nbsp;</p>
<p>더미처리는 인덱스를 0 , 1 , 2  ... 이런식으로 분류하는 것이 아닌 희소행렬을 만들어 분류한다.</p>
<p>예를들면 &#39;OCEAN&#39; 은 [1 0 0 0 0]  , &#39;NEAR BAY&#39; 는 [0 0 0 1 0] 이런식으로 해당되는 피쳐값만 1로 표시하고 나머지는 0으로 표시하는 샘이다.  이렇게 인코딩 하면 위와 같이 연관성이 없는데 연관성이 있는 것 처럼 판별하는 상황을 방지할 수 있다.</p>
<pre><code class='language-python' lang='python'>from sklearn.preprocessing import OneHotEncoder #OrdinalEncoder의 문제점을 해결하기 위한 OneHot Encoding
cat_encoder = OneHotEncoder()

housing_cat_1hot = cat_encoder.fit_transform(housing_cat)
</code></pre>
<p>&nbsp;</p>
<p><strong>사용자 설정 변환기 만들기</strong></p>
<p>&nbsp;</p>
<p>여태까지는 파이썬의 sklearn에서 제공하는 표준 클래스들을 가져다가 사용하였지만, 실제 모델을 만들 때는 모델에 꼭 필요한 사용자 설정 변환기를 직접 제작해야 하는 상황이 있을 수 있다. 그래서 sklearn에서는 sklearn의 기존 변환기 클래스 들과 같은 내장함수(fit, transform, fit_transform)들을 사용할 수 있게 BaseEstimator와 TransformerMixin이 존재한다.</p>
<p>&nbsp;</p>
<p>다음은 이를 활용하여 &#39;rooms_per_household&#39; 와 &#39;population_per_house_hold&#39; 값을 데이터에 추가하고 선택하기에 따라서 &#39;bedrooms_per_room&#39;을 추가할 수 있는 클래스이다. </p>
<pre><code class='language-python' lang='python'>from sklearn.base import BaseEstimator,TransformerMixin

rooms_ix,bedrooms_ix,population_ix,households_ix = 3,4,5,6

class CombinedAttributesAdder(BaseEstimator,TransformerMixin) :
    def __init__(self,add_bedrooms_per_room = True) : #생성자 (default = add_bedrooms_per_room)
        self.add_bedrooms_per_room = add_bedrooms_per_room #단위 방개수 당 침실수
    def fit(self,X,y = None) :
        return self
    def transform(self,X) :
        rooms_per_household = X[:,rooms_ix]/X[:,households_ix] # 단위 가구수당 방 개수
        population_per_household = X[:,population_ix]/X[:,rooms_ix] #단위 방개수 당 인구수
        
        if self.add_bedrooms_per_room :
            bedrooms_per_room = X[:,bedrooms_ix]/X[:,rooms_ix]
            return np.c_[X,rooms_per_household,population_per_household,bedrooms_per_room] # 단위 방개수 당 침실수를 True로 선택한 경우 리턴
        else :
            return np.c_[X,rooms_per_household,population_per_household] # 단위 방개수 당 침실수를 False로 선택한 경우 리턴

attr_adder = CombinedAttributesAdder(add_bedrooms_per_room = False) #객체생성
housing_extra_attribs = attr_adder.transform(housing.values)
</code></pre>
<p>&nbsp;</p>
<p><strong> 스케일링</strong></p>
<p>&nbsp;</p>
<p>모델을 학습시킬 때 각 피쳐값들의 스케일이 심하게 다르면 제대로 학습이 이루어 지지 않는다. 따라서 스케일을 맞춰줘야 한다. 일반적으로 StandardScaler와 MinMaxScaler를 많이 쓴다.</p>
<p>&nbsp;</p>
<ol start='' >
<li><p>StandardScaler(정규화)</p>
<p>정규화 스케일러는 기존 변수의 범위를 정규분포로 변환하는 것이다 따라서 데이터들의 평균을 0 분산을 1로 만들어 준다. 데이터의 최대 최소를 모를 때 사용하기 좋으며 이상치에 매우 민감하므로 이상치를 최대한 제거하고 사용하는 것이 좋다.</p>
</li>

</ol>
<pre><code class='language-python' lang='python'>from sklearn.preprocessing import StandardScaler

std = StandardScaler()
std_data = std.fit_transform(data)
</code></pre>
<ol start='2' >
<li><p>MinMaxScaler(최대최소변환)</p>
<p>최대최소 스케일러는 데이터의 값들을 최소값과 최대값을 기준으로 0~1사이로 맞추는 것이다.</p>
<p>정규화 스케일러보다는 이상치에 덜 민감하지만 그래도 이상치가 너무 많을 경우 학습이 제대로 이루어지지 않을 수 있으므로 최대한 이상치를 제거하고 사용해야 한다. 만약 0~1로 맞추고 싶지 않다면 feature_range 매개변수를 이용하여 값을 바꿔줄 수 있다.</p>
</li>

</ol>
<pre><code class='language-python' lang='python'>from sklearn.preprocessing import MinMaxScaler

mm = MinMaxScaler()
mm_data = mm.fit_transform(data)
</code></pre>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><strong> 변환 파이프라인 제작</strong></p>
<p>&nbsp;</p>
<p>인공지능 모델을 완성하여 배포했을 경우 시간이 지남에 따라 과거의 데이터로만 학습한 모델은 예측 적중률이 떨어질 수 밖에 없다. 따라서 주기적으로 새로운 데이터를 입력하여 학습시켜야 하는데 이때마다 전처리 코드를 새로 작성할 수 없다. 따라서 새로운 데이터가 들어올 때 마다 자동으로 정해진 프로세스를 거치는 전처리 클래스가 필요하다. sklearn의 pipeline은 이런 전처리 과정을 하나의 클래스를 묶을 수 있는 클래스를 제공한다.</p>
<p>&nbsp;</p>
<pre><code class='language-python' lang='python'>from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

num_pipeline = Pipeline([
    (&#39;imputer&#39;,SimpleImputer(strategy = &#39;median&#39;)), #객체이름(아무거나) , estimator
    (&#39;attribs_adder&#39;,CombinedAttributesAdder()),
    (&#39;std_scaler&#39;,StandardScaler()),
])

housing_num_tr = num_pipeline.fit_transform(housing_num) # 결측치처리 fit_transform 후 CombinedAttributesAdder fit_transform 후 StandartScaler 의 fit_transform을 진행
</code></pre>
<p>&nbsp;</p>
<p>파이프라인 안의 각 클래스들은 위에서 부터 순서대로 데이터를 fit_transform 하여 다음 클래스로 또 fit_transform하여 다음 클래스로 넘긴다.</p>
<p>&nbsp;</p>
<p>그러나 위의 num_pipeline은 숫자형 피쳐값들에 대한 전처리 만들 제공한다.(실제로 10번째 줄에 housing_num을 매개변수로 넣었다.) 모델의 학습에 필요한 텍스트 데이터는 파이프라인을 하나 더 만들어서 따로 전처리를 해줘야 하는데, 이는 효율적이지 못하다. 따라서 sklearn에서 텍스트형 카테고리 데이터와 숫자 데이터를 동시에 전처리 할 수 있는 파이프라인을 제공한다.</p>
<pre><code class='language-python' lang='python'>from sklearn.compose import ColumnTransformer

num_attribs = list(housing_num) #housing_num의 피쳐이름들
cat_attribs = [&#39;ocean_proximity&#39;] #housing 텍스트 데이터의 피쳐이름(한개임)

full_pipeline = ColumnTransformer([
    (&#39;num&#39;,num_pipeline,num_attribs), #튜플이름(아무거나), 그에적용할파이프라인,피쳐이름
    (&#39;cat&#39;,OneHotEncoder(),cat_attribs) 
])

housing_prepared = full_pipeline.fit_transform(housing)
</code></pre>
<p>&nbsp;</p>
<p>파이프라인 내에 이름(아무거나쓰면된다), 적용할 파이프라인 이름, 피쳐이름(들) 을 차례로 쓰면 된다. 8번째 줄 같은 경우는 전처리를 할 때 OneHotEncoding(더미처리) 만 하면 되므로 굳이 파이프라인을 만들지 않고 하나의 전처리 클래스만 적어주면 된다.</p>
<p>cf) 파이프라인으로 전처리된 데이터는 pandas의 데이터 프레임이 아니라 numpy의 어레이 이므로 데이터 프레임으로 사용하고 싶다면 다시 변환을 해줘야 한다.</p>
</body>
</html>
